<!DOCTYPE html>
<html>
<head>
    <title>Lateral Inhibition in CNN</title>
</head>
<body>
<h2>Modeling Lateral Inhibition in Convolutional Neural Networks</h2>
<p style="margin-bottom: 5px;">
    Students: Quinton Denman, Julian Lehnen, Dávid Sebők , Tonio Weidler;
    Supervisors: Mario Senden, Gerhard Weiss, Kurt Driessens;
    Semester: 2019;
</p>

<figure style="float: left; width: min-content; height: min-content;">
    <img alt="" src="2019_Lehnen_img_1.png" style="width: 400px; height: 570px;">
    <figcaption>Fig 1. - Column B receives a strong excitation and inhibits the activity of columns A and C.
    </figcaption>
</figure>

<h4>Problem statement and motivation:</h4>
<p align="justify">
    A Convolutional Neural Network (CNN) mimics the way that a human brain processes visual information. Imagine a 5
    year-old learning different animals. A picture of the animal is shown to them and they're told that it is, for
    example, a giraffe. In the same way, a CNN is shown many pictures and told that the image depicts a giraffe: the CNN
    is trained on labelled data. This can be extended to learn a lot more than this example, but the truth is, a CNN is
    only a crude copy of how the brain works. The neurons are modelled as The structure of the brain is extremely
    complicated but researchers in Neuroscience are constantly making strides in understanding its inner workings. The
    goal of our project is to take some of that new understanding and incorporate it into CNNs. By emulating the brain
    more closely we hope to improve CNNs (for example, needing less images to train it to recognise that giraffe!) or at
    least gain understanding about the brain's functioning by drawing conclusions from observations in the mathematical
    model.
</p>
<p align="justify">
    The specific concept we will be trying to replicate is called Lateral Inhibition. The brain has billions of neurons
    (brain cells) grouped into sectors with each sector handling different tasks. All the neurons responsible for
    handling vision are in one section of the brain called the visual cortex and were found to be arranged into a series
    of columns. Isaacson and Scanziani (2011) found that some of these columns were responsible for identifying and
    processing different orientations of a line (For example, the difference between a straight line and a diagonal
    line, see figure 1). Furthermore, all the columns that are responsible for this are lined up next to each other.
    They are
    organised based on the similarity of the orientations they represent (e.g. a column identifying a 90 degree line is
    next to a 95 degree line and a 85 degree line). So when the eye sees a horizontal line, the column (in the visual
    cortex) representing that horizontal line activates. Additionally, these columns have the ability to influence their
    neighbours, either boosting the chance they fire or reducing it. For example, imagine three columns A,B and C. The
    visual input relates to the orientation for column B. Column B then reduces or boosts the values of A and C. In
    return, A and C reduce or boost the value of column B. This effectively pushes or dimmes B’s signal, ensuring that
    it is the chosen column.
</p>
<p align="justify">
    We hope that introducing this concept of lateral inhibition into the structure of CNN’s will improve their
    performance and produce an ordered structure like the columns. We will then investigate how or if this is beneficial
    to the CNN.
</p>
<p align="justify">
    To achieve this we propose three approaches that successively try to tackle their predecessors’ key problems. In our
    first approach we simply apply lateral inhibition as a single shot operation, altering the activity of the model in
    one step. However, in the brain, neuronal activity is an ongoing process, incorporating a time factor. In CNNs, we
    do not have such a factor of time, but rather one beginning-to-end calculation of an output. Problematically, the
    concept of lateral inhibition is heavily dependent on the time factor: If a column is inhibited, the effect it can
    later have on other columns will diminish and after a while all activity stabilizes. Our single-shot approach does
    not capture this characteristic. To account for this, our second idea is to repeat the step of inhibition for some
    number of steps, always applied on the result of the previous step. This hopefully brings the result closer to a
    stabilized state. However, this process is slow due to the repeated calculations and it is also still not exact. In
    our third approach we therefore attempt to mathematically determine the state of the neurons at the point at which
    they stabilize and then calculate this in one step.
</p>

<h4>Research questions:</h4>
<ul>
    <li>
        Can an improvement in performance or training speed on classic benchmark tasks be
        achieved with the proposed models of lateral inhibition in convolutional neural networks?
    </li>
    <li>
        What are possible models of lateral inhibition inside convolutional neural networks?
    </li>
    <li>
        How do these models benefit the neural networks?
    </li>
    <li>
        Will one of the proposed models of lateral inhibition in a convolutional neural
        network cause an ordering of filters that follows some characteristic of the preferred
        stimuli of each filter?
    </li>
    <li>
        If such an ordering can be observed, is it consistent over multiple training runs
        despite a varying random weight initialization?
    </li>
</ul>

<h4>Main outcomes:</h4>
<ul>
    <li>
        Introducing lateral inhibition improves CNN by utilising training data more efficiently, that is, given the same
        amount of training data a CNN with lateral inhibition provides a higher test accuracy than a CNN without out.
    </li>
    <li>
        The introduction of lateral inhibition imposes an ordering on the filters within the respective CNN
    </li>
</ul>

<h4>References:</h4>
Isaacson, Jeffry S. and Scanziani, Massimo (2011). How inhibition shapes cortical activity. Neuron 72(2), 231-243

<h4>Downloads:</h4>
<a href="" target="_blank" rel="noopener">Final report</a>
<a href="" target="_blank" rel="noopener">Final presentation</a>

</body>
</html>